{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import scripts with necessary imports, models and train-test loop logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import*\n",
    "from train_val_test import*\n",
    "from models import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import preprocessed data from external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = 'preprocessed_ppg512hz.npy'\n",
    "y_file = 'y_ppg512hz.npy'\n",
    "X_padded = np.load(X_file)\n",
    "y = np.load(y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1533, 640, 1)\n",
      "X_val shape: (1533, 640, 1)\n",
      "X_test shape: (2045, 640, 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels to binary (0 for classes 1 and 2, 1 for class 3)\n",
    "y = np.array(y)\n",
    "y_binary = np.where(y == 3, 1, 0)\n",
    "\n",
    "# Train-validation-test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_padded, y_binary, test_size=0.4, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, train_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape the data to add a channel dimension for the CNN\n",
    "X_train = X_train[..., np.newaxis].squeeze(-1)\n",
    "X_val = X_val[..., np.newaxis].squeeze(-1)\n",
    "X_test = X_test[..., np.newaxis].squeeze(-1)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "input_shape = (X_train_tensor.shape[0], X_train_tensor.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation loop\n",
    "num_epochs = 200\n",
    "patience = 50\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_model, best_hyperparams = grid_search(train_loader, val_loader, num_epochs, patience)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy, y_test_true, y_test_pred = evaluate_model(best_model, test_loader, criterion)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Prediction\n",
    "y_pred_classes = (np.array(y_test_pred) > 0.5).astype(int).flatten()\n",
    "y_test_classes = y_test_true\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision = precision_score(y_test_classes, y_pred_classes)\n",
    "recall = recall_score(y_test_classes, y_pred_classes)\n",
    "f1 = f1_score(y_test_classes, y_pred_classes)\n",
    "auc = roc_auc_score(y_test_classes, y_test_pred)\n",
    " \n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in best_model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
